{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jan  5 15:10:40 2022\n",
    "\n",
    "@author: mostafa3_local  (Alireza Mostafavi)\n",
    "\"\"\"\n",
    "# A network is developed for pothole semantic segmentation and\n",
    "# depth estimation. First of all, the model is trsined for\n",
    "# pothole segmentation and the trianed model for segmentaion\n",
    "# is trianed for pothole depth estimation. By this approach, the best results\n",
    "# are optained for both segmentation and depth estimation.\n",
    "# The input for segmentaion is depth map. However, the input for\n",
    "# segmentation can be changed to RGB image but the peformance will\n",
    "# be reduced. The input for depth estimatin is RGB image.\n",
    "\n",
    "# For training depth estimation network, first of all I pretrained it for segmentation.\n",
    "# The resason is that all monocular depth estimation networks have used a powerfull backbone\n",
    "# such as DenseNet or Resnet (DenseNet and Resnet are image classification algorithm).\n",
    "# However we did not want to use these kind of heavy network with over 40M parameters.\n",
    "# As a result I decided to create my own backbone. So I fisrt of all pretrain the network for\n",
    "# image segmentation and then continue training for depth estimation.\n",
    "\n",
    "#%% importing data\n",
    "import os\n",
    "from progress.bar import Bar\n",
    "import numpy as np\n",
    "import cv2\n",
    "# create npy from the dataset\n",
    "TRAIN_RGB_PATH = './data/train/rgb/'\n",
    "TRAIN_DEPTH_PATH = './data/train/depths/'\n",
    "TEST_DEPTH_PATH = './data/test/depths/'\n",
    "TEST_RGB_PATH = './data/test/rgb/'\n",
    "\n",
    "rgb_train = [file for file in os.listdir(TRAIN_RGB_PATH) if file.endswith('JPG')]\n",
    "depth_train = os.listdir(TRAIN_DEPTH_PATH)\n",
    "depth_test = os.listdir(TEST_DEPTH_PATH)\n",
    "rgb_test = os.listdir(TEST_RGB_PATH)\n",
    "\n",
    "# make sure the length of the dataset is the same\n",
    "assert len(rgb_train) == len(depth_train), 'The length of the dataset is not the same, {} rgb vs {} depths'.format(len(rgb_train), len(depth_train))\n",
    "assert len(rgb_test) == len(depth_test), \"The length of the test dataset is not equal to the length of the test dataset\"\n",
    "# pickle the data using numpy\n",
    "train_rgb_npy = []\n",
    "train_depth_npy = []\n",
    "test_depth_npy = []\n",
    "test_rgb_npy = []\n",
    "\n",
    "# create a progress bar\n",
    "progress_bar = Bar('Processing', max=len(rgb_train)+len(rgb_test)+len(depth_train)+len(depth_test))\n",
    "# npy files do not exist, lets create them here. This will take a while.\n",
    "if not os.path.exists('./data/npy/train_rgb.npy'):\n",
    "    for file_name in rgb_train:\n",
    "        img = cv2.imread(TRAIN_RGB_PATH + file_name)\n",
    "        train_rgb_npy.append(img)\n",
    "        progress_bar.next()\n",
    "\n",
    "    for file_name in depth_train:\n",
    "        img = cv2.imread(TRAIN_DEPTH_PATH + file_name, cv2.IMREAD_GRAYSCALE)\n",
    "        train_depth_npy.append(img)\n",
    "        progress_bar.next()\n",
    "\n",
    "    for file_name in depth_test:\n",
    "        img = cv2.imread(TEST_DEPTH_PATH + file_name, cv2.IMREAD_GRAYSCALE)\n",
    "        test_depth_npy.append(img)\n",
    "        progress_bar.next()\n",
    "\n",
    "    for file_name in rgb_test:\n",
    "        img = cv2.imread(TEST_RGB_PATH + file_name)\n",
    "        test_rgb_npy.append(img)\n",
    "        progress_bar.next()\n",
    "    progress_bar.finish()\n",
    "    # save the npy files\n",
    "    if not os.path.exists(\"./data/npy\"):\n",
    "        os.makedirs(\"./data/npy\")\n",
    "    np.save('./data/npy/train_rgb.npy', train_rgb_npy)\n",
    "    np.save('./data/npy/train_depth.npy', train_depth_npy)\n",
    "    np.save('./data/npy/test_depth.npy', test_depth_npy)\n",
    "    np.save('./data/npy/test_rgb.npy', test_rgb_npy)\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('./data/npy/train_rgb.npy'):\n",
    "    test_rgb = np.load('data/npy/test_rgb.npy')\n",
    "    test_depth = np.load('data/npy/test_depth.npy')\n",
    "    train_rgb = np.load('data/npy/train_rgb.npy')\n",
    "    train_depth = np.load('data/npy/train_depth.npy')\n",
    "    # train_label = np.load('/home/mostafa3_local/Documents/data/train_label.npy')\n",
    "    # test_label = np.load('/home/mostafa3_local/Documents/data/test_label.npy')\n",
    "    # train_label = train_label.reshape(420, 400, 400, 1)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#indices = np.random.permutation(test_rgb.shape[0])\n",
    "indices = range(test_rgb.shape[0])\n",
    "test_idx, validation_idx = indices[:100], indices[100:]\n",
    "test_rgb, validation_rgb = test_rgb[test_idx,:], test_rgb[validation_idx,:]\n",
    "test_depth, validation_depth = test_depth[test_idx,:], test_depth[validation_idx,:]\n",
    "test_label, validation_label = test_label[test_idx,:], test_label[validation_idx,:]\n",
    "\n",
    "test_label = test_label.reshape(test_label.shape[0],400,400,1)\n",
    "validation_label = validation_label.reshape(validation_label.shape[0],400,400,1)\n",
    "\n",
    "plt.imshow(test_rgb[20])\n",
    "plt.imshow(test_depth[20])\n",
    "plt.imshow(test_label[20])\n",
    "\n",
    "#%% preprocessing\n",
    "import math\n",
    "batch_size = 20\n",
    "total_samples = len(train_rgb)\n",
    "n_iterations = math.ceil(total_samples/batch_size)\n",
    "print(n_iterations)\n",
    "validation_iteration = validation_rgb.shape[0]/batch_size \n",
    "print(validation_iteration)\n",
    "raise Exception('stop')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "\n",
    "#pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Device configuration\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "cuda = torch.device('cuda')\n",
    "cuda0 = torch.device('cuda:0')\n",
    "device = torch.device('cuda:2')\n",
    "\n",
    "print(device)\n",
    "\n",
    "train_rgb_tns = torch.from_numpy(np.transpose(train_rgb,(0,3,1,2)))\n",
    "train_depth_tns = torch.from_numpy(np.transpose(train_depth,(0,3,1,2)))\n",
    "train_label_tns = torch.from_numpy(np.transpose(train_label,(0,3,1,2)))\n",
    "\n",
    "valid_rgb_tns = torch.from_numpy(np.transpose(validation_rgb,(0,3,1,2)))\n",
    "valid_depth_tns = torch.from_numpy(np.transpose(validation_depth,(0,3,1,2)))\n",
    "valid_label_tns = torch.from_numpy(np.transpose(validation_label,(0,3,1,2)))\n",
    "\n",
    "test_rgb_tns = torch.from_numpy(np.transpose(test_rgb,(0,3,1,2)))\n",
    "test_depth_tns = torch.from_numpy(np.transpose(test_depth,(0,3,1,2)))\n",
    "test_label_tns = torch.from_numpy(np.transpose(test_label,(0,3,1,2)))\n",
    "#%% learning rate scheduling\n",
    "\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "class PolynomialLRDecay(_LRScheduler):\n",
    "    \"\"\"Polynomial learning rate decay until step reach to max_decay_step\n",
    "    \n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        max_decay_steps: after this step, we stop decreasing learning rate\n",
    "        end_learning_rate: scheduler stoping learning rate decay, value of learning rate must be this value\n",
    "        power: The power of the polynomial.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, optimizer, max_decay_steps, end_learning_rate=0.0001, power=1.0):\n",
    "        if max_decay_steps <= 1.:\n",
    "            raise ValueError('max_decay_steps should be greater than 1.')\n",
    "        self.max_decay_steps = max_decay_steps\n",
    "        self.end_learning_rate = end_learning_rate\n",
    "        self.power = power\n",
    "        self.last_step = 0\n",
    "        super().__init__(optimizer)\n",
    "        \n",
    "    def get_lr(self):\n",
    "        if self.last_step > self.max_decay_steps:\n",
    "            return [self.end_learning_rate for _ in self.base_lrs]\n",
    "\n",
    "        return [(base_lr - self.end_learning_rate) * \n",
    "                ((1 - self.last_step / self.max_decay_steps) ** (self.power)) + \n",
    "                self.end_learning_rate for base_lr in self.base_lrs]\n",
    "    \n",
    "    def step(self, step=None):\n",
    "        if step is None:\n",
    "            step = self.last_step + 1\n",
    "        self.last_step = step if step != 0 else 1\n",
    "        if self.last_step <= self.max_decay_steps:\n",
    "            decay_lrs = [(base_lr - self.end_learning_rate) * \n",
    "                         ((1 - self.last_step / self.max_decay_steps) ** (self.power)) + \n",
    "                         self.end_learning_rate for base_lr in self.base_lrs]\n",
    "            for param_group, lr in zip(self.optimizer.param_groups, decay_lrs):\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "\n",
    "#%% defining depthwise separable convolutions\n",
    "\n",
    "class depthwise_separable_conv(nn.Module):\n",
    " def __init__(self, nin, nout,n_stride,n_padding): \n",
    "   super(depthwise_separable_conv, self).__init__() \n",
    "   kernels_per_layer =1\n",
    "   self.depthwise = nn.Conv2d(nin, nin * kernels_per_layer, kernel_size=3, padding=n_padding, groups=nin,stride = n_stride) \n",
    "   self.pointwise = nn.Conv2d(nin * kernels_per_layer, nout, kernel_size=1) \n",
    "   self.bn = nn.BatchNorm2d(int(nout))\n",
    "   self.relu = nn.ReLU(inplace=True)\n",
    "   \n",
    " def forward(self, x): \n",
    "   out = self.depthwise(x)\n",
    "   out = self.relu(out)\n",
    "   out = self.pointwise(out) \n",
    "   out = self.bn(out)\n",
    "   out = self.relu(out)\n",
    "   return out\n",
    "\n",
    "class depthwise_separable_conv_sig(nn.Module):\n",
    " def __init__(self, nin, nout,n_stride,n_padding): \n",
    "   super(depthwise_separable_conv_sig, self).__init__() \n",
    "   kernels_per_layer =1\n",
    "   self.depthwise = nn.Conv2d(nin, nin * kernels_per_layer, kernel_size=3, padding=n_padding, groups=nin,stride = n_stride) \n",
    "   self.pointwise = nn.Conv2d(nin * kernels_per_layer, nout, kernel_size=1) \n",
    "   self.bn = nn.BatchNorm2d(int(nout))\n",
    "   self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    " def forward(self, x): \n",
    "   out = self.depthwise(x)\n",
    "   out = self.relu(out)\n",
    "   out = self.pointwise(out) \n",
    "   out = self.bn(out)\n",
    "   out = torch.sigmoid(out)\n",
    "   return out\n",
    "\n",
    "\n",
    "#%% Attention based on Atrous Special Pooling Pyramid\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,n_input_channels):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(n_input_channels, n_input_channels // 4, 1),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(n_input_channels // 4, n_input_channels, 1))\n",
    "\n",
    "        self.PW = nn.Conv2d(in_channels =n_input_channels, out_channels = n_input_channels//2, kernel_size = 1, stride=1, padding='same')\n",
    "        self.dilated_conv1 = nn.Sequential(nn.Conv2d(n_input_channels,n_input_channels, kernel_size=5, stride=1, padding='same',dilation = 2, groups=n_input_channels),\n",
    "                                           nn.Conv2d(n_input_channels, n_input_channels//2, kernel_size=1),\n",
    "                                           nn.ReLU()) \n",
    "        self.dilated_conv2 = nn.Sequential(nn.Conv2d(n_input_channels,n_input_channels, kernel_size=5, stride=1, padding='same',dilation = 4, groups=n_input_channels),\n",
    "                                           nn.Conv2d(n_input_channels, n_input_channels//2, kernel_size=1),\n",
    "                                           nn.ReLU()) \n",
    "        self.dilated_conv3 = nn.Sequential(nn.Conv2d(n_input_channels,n_input_channels, kernel_size=5, stride=1, padding='same',dilation = 8, groups=n_input_channels),\n",
    "                                           nn.Conv2d(n_input_channels, n_input_channels//2, kernel_size=1),\n",
    "                                           nn.ReLU()) \n",
    "        \n",
    "        self.conv1by1 = nn.Conv2d(in_channels =n_input_channels*2, out_channels = n_input_channels, kernel_size = 1, stride=1, padding='same')\n",
    "\n",
    "    def forward(self, input):\n",
    "          dimention = input.size()\n",
    "          avg_pool = F.adaptive_avg_pool2d(input, (1, 1))\n",
    "          avg_pool = torch.flatten(avg_pool, 1)\n",
    "\n",
    "          max_pool = F.adaptive_max_pool2d(input, (1, 1))\n",
    "          max_pool = torch.flatten(max_pool, 1)\n",
    "\n",
    "          max_pool = self.fc(max_pool)\n",
    "          avg_pool = self.fc(avg_pool)\n",
    "\n",
    "          channel_attention = torch.sigmoid(avg_pool + max_pool)\n",
    "          channel_attention = input*channel_attention.view(dimention[0],dimention[1],1,1)\n",
    "\n",
    "          dilated_conv1 = self.dilated_conv1(input)\n",
    "          dilated_conv2 = self.dilated_conv2(input)\n",
    "          dilated_conv3 = self.dilated_conv3(input)\n",
    "          pw = self.PW(input)\n",
    "          \n",
    "          spatial_attention = torch.cat((dilated_conv1, dilated_conv2,dilated_conv3,pw), 1)\n",
    "          spatial_attention = torch.sigmoid(self.conv1by1(spatial_attention)) \n",
    "          \n",
    "          attention = torch.cat((channel_attention,spatial_attention),1)\n",
    "          return attention\n",
    "\n",
    "#%% Attention based on Dual attention module ( this performs better) and building the model\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,n_input_channels):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(n_input_channels, n_input_channels // 4, 1),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(n_input_channels // 4, n_input_channels, 1))\n",
    "\n",
    "        #self.dilated_conv1 = dilated_separable_conv(n_input_channels,1,n_input_channels//2,4)\n",
    "        #self.dilated_conv2 = dilated_separable_conv(n_input_channels,1,n_input_channels//2,8)\n",
    "        #self.dilated_conv3 = dilated_separable_conv(n_input_channels,1,n_input_channels//2,12)\n",
    "        self.dilated_conv1 = nn.Sequential(nn.Conv2d(n_input_channels,n_input_channels, kernel_size=5, stride=1, padding='same',dilation = 4, groups=n_input_channels),\n",
    "                                           nn.Conv2d(n_input_channels, n_input_channels//2, kernel_size=1)) \n",
    "        self.dilated_conv2 = nn.Sequential(nn.Conv2d(n_input_channels,n_input_channels, kernel_size=5, stride=1, padding='same',dilation = 8, groups=n_input_channels),\n",
    "                                           nn.Conv2d(n_input_channels, n_input_channels//2, kernel_size=1)) \n",
    "        self.dilated_conv3 = nn.Sequential(nn.Conv2d(n_input_channels,n_input_channels, kernel_size=5, stride=1, padding='same',dilation = 12, groups=n_input_channels),\n",
    "                                           nn.Conv2d(n_input_channels, n_input_channels//2, kernel_size=1)) \n",
    "        \n",
    "        \n",
    "        self.conv1by1 = nn.Conv2d(in_channels =n_input_channels*3//2, out_channels = n_input_channels, kernel_size = 1, stride=1, padding='same')\n",
    "\n",
    "    def forward(self, input):\n",
    "          dimention = input.size()\n",
    "          avg_pool = F.adaptive_avg_pool2d(input, (1, 1))\n",
    "          avg_pool = torch.flatten(avg_pool, 1)\n",
    "\n",
    "          max_pool = F.adaptive_max_pool2d(input, (1, 1))\n",
    "          max_pool = torch.flatten(max_pool, 1)\n",
    "\n",
    "          max_pool = self.fc(max_pool)\n",
    "          avg_pool = self.fc(avg_pool)\n",
    "\n",
    "          channel_attention = torch.sigmoid(avg_pool + max_pool)\n",
    "          channel_attention = input*channel_attention.view(dimention[0],dimention[1],1,1)\n",
    "\n",
    "          dilated_conv1 = self.dilated_conv1(channel_attention)\n",
    "          dilated_conv2 = self.dilated_conv2(channel_attention)\n",
    "          dilated_conv3 = self.dilated_conv3(channel_attention)\n",
    "\n",
    "          spatial_attention = torch.cat((dilated_conv1, dilated_conv2,dilated_conv3), 1)\n",
    "          spatial_attention = torch.sigmoid(self.conv1by1(spatial_attention)) \n",
    "\n",
    "          Dual_attention = channel_attention*spatial_attention\n",
    "          return Dual_attention\n",
    "\n",
    "\n",
    "\n",
    "class NET(nn.Module):\n",
    "    def __init__(self,features=[16, 32, 64, 128,256]):\n",
    "        super(NET, self).__init__()\n",
    "        self.entry = nn.Sequential(\n",
    "        nn.Conv2d(3, 3*2, kernel_size=7, padding=3, groups=3,stride =2), \n",
    "        nn.Conv2d(3*2, features[0], kernel_size=1),\n",
    "        nn.ReLU()) \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.down1 = depthwise_separable_conv(features[0],features[1],1,1)\n",
    "        self.down2 = depthwise_separable_conv(features[1]+features[0],features[2],2,1)\n",
    "        self.down3 = depthwise_separable_conv(features[2],features[2],1,1)\n",
    "        self.down4 = depthwise_separable_conv(features[2]*2,features[3],2,1)\n",
    "        self.down5 = depthwise_separable_conv(features[3],features[3],1,1)\n",
    "        self.down6 = depthwise_separable_conv(features[3]*2,features[4],2,1)\n",
    "        self.mid1 = depthwise_separable_conv(features[4],features[4],1,1)\n",
    "        self.Attention1 = Attention(features[4])\n",
    "        self.Conv1 =  nn.Conv2d(in_channels =features[4]*2, out_channels = features[4], kernel_size = 1, stride=1, padding='same')\n",
    "        self.mid2 = depthwise_separable_conv(features[4],features[4],1,1)\n",
    "        \n",
    "        self.mid1_1 = depthwise_separable_conv(features[4],features[4],1,1)\n",
    "        self.Attention1_1 = Attention(features[4])\n",
    "        self.Conv1_1 =  nn.Conv2d(in_channels =features[4]*2, out_channels = features[4], kernel_size = 1, stride=1, padding='same')\n",
    "        self.mid2_1 = depthwise_separable_conv(features[4],features[4],1,1)\n",
    "        \n",
    "        self.mid1_2 = depthwise_separable_conv(features[4],features[4],1,1)\n",
    "        self.Attention1_2 = Attention(features[4])\n",
    "        self.Conv1_2 =  nn.Conv2d(in_channels =features[4]*2, out_channels = features[4], kernel_size = 1, stride=1, padding='same')\n",
    "        self.mid2_2 = depthwise_separable_conv(features[4],features[4],1,1)\n",
    "\n",
    "        self.UPsample1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=None)\n",
    "        self.UP1 = depthwise_separable_conv(features[4],features[3],1,1)\n",
    "        self.UP2 = depthwise_separable_conv(features[3]*2,features[3],1,1)\n",
    "        self.Attention2 = Attention(features[3])\n",
    "        self.Conv2 =  nn.Conv2d(in_channels =features[3]*2, out_channels = features[3], kernel_size = 1, stride=1, padding='same')\n",
    "        \n",
    "        self.UPsample2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=None)\n",
    "        self.UP3 = depthwise_separable_conv(features[3],features[2],1,1)\n",
    "        self.UP4 = depthwise_separable_conv(features[2]*2,features[2],1,1)\n",
    "        self.Attention3 = Attention(features[2])\n",
    "        self.Conv3 =  nn.Conv2d(in_channels =features[2]*2, out_channels = features[2], kernel_size = 1, stride=1, padding='same')\n",
    "\n",
    "        self.UPsample3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=None)\n",
    "        self.UP5 = depthwise_separable_conv(features[2],features[1],1,1)\n",
    "        self.UP6 = depthwise_separable_conv(features[1]*2,features[1],1,1)\n",
    "        self.Attention4 = Attention(features[1])\n",
    "        self.Conv4 =  nn.Conv2d(in_channels =features[1]*2, out_channels = features[1], kernel_size = 1, stride=1, padding='same')\n",
    "        \n",
    "        self.UPsample4 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=None)\n",
    "        self.UP7 = depthwise_separable_conv(features[1],features[0],1,1)\n",
    "        self.UP8 = depthwise_separable_conv_sig(features[0],1,1,1)\n",
    "        #self.UP9 = depthwise_separable_conv_sig(4,1,1,1)\n",
    "\n",
    "  \n",
    "    def forward(self, input):           #H*W\n",
    "        x0 = self.entry(input)          #H/2*W/2\n",
    "        x1 = self.down1(x0)             #H/2*W/2\n",
    "        x2 = torch.cat((x0, x1), 1)\n",
    "        x2 = self.down2(x2)             #H/4*W/4\n",
    "        x2 = self.dropout(x2)\n",
    "        x3 = self.down3(x2)             #H/4*W/4\n",
    "        x4 = torch.cat((x2, x3), 1)\n",
    "        x4 = self.down4(x4)             #H/8*W/8\n",
    "        x4 = self.dropout(x4)\n",
    "        x5 = self.down5(x4)             #H/8*W/8\n",
    "        x6 = torch.cat((x4, x5), 1)\n",
    "        x6 = self.down6(x6)             #H/16*W/16\n",
    "        x6 = self.dropout(x6)\n",
    "        mid1 = self.mid1(x6)            #H/16*W/16\n",
    "        attention1 = self.Attention1(x6)\n",
    "        conv1 = torch.relu(self.Conv1(torch.cat((attention1,mid1),1)))\n",
    "        mid2 = self.mid2(conv1)                     #H/16*W/16\n",
    "        \n",
    "        mid1_1 = self.mid1_1(mid2)                  #H/16*W/16\n",
    "        attention1_1 = self.Attention1_1(mid2)\n",
    "        conv1_1 = torch.relu(self.Conv1_1(torch.cat((attention1_1,mid1_1),1)))\n",
    "        mid2_1 = self.mid2_1(conv1_1)               #H/16*W/16\n",
    "        \n",
    "        \n",
    "        mid1_2 = self.mid1_2(mid2_1)                  #H/16*W/16\n",
    "        attention1_2 = self.Attention1_2(mid2_1)\n",
    "        conv1_2 = torch.relu(self.Conv1_2(torch.cat((attention1_2,mid1_2),1)))\n",
    "        mid2_2 = self.mid2_2(conv1_2)               #H/16*W/16\n",
    "        \n",
    "        upsample1 = self.UPsample1(mid2_2)          #H/8*W/8\n",
    "        up1 = self.UP1(upsample1)                   #H/8*W/8\n",
    "        cat1 = torch.cat((up1,x5),1)    \n",
    "        up2 = self.UP2(cat1)                        #H/8*W/8\n",
    "        attention2 = self.Attention2(up1)\n",
    "        conv2 = torch.relu(self.Conv2(torch.cat((attention2,up2),1)))\n",
    "        \n",
    "        upsample2 = self.UPsample2(conv2)           #H/4*W/4\n",
    "        up3 = self.UP3(upsample2)                   #H/4*W/4\n",
    "        cat2 = torch.cat((up3,x3),1)    \n",
    "        up4 = self.UP4(cat2)                        #H/4*W/4\n",
    "        attention3 = self.Attention3(up3)\n",
    "        conv3 = torch.relu(self.Conv3(torch.cat((attention3,up4),1)))\n",
    "        \n",
    "        upsample3 = self.UPsample3(conv3)            #H/2*W/2\n",
    "        up5 = self.UP5(upsample3)                    #H/2*W/2\n",
    "        cat3 = torch.cat((up5,x1),1)    \n",
    "        up6 = self.UP6(cat3)                         #H/2*W/2\n",
    "        attention4 = self.Attention4(up5)\n",
    "        conv4 = torch.relu(self.Conv4(torch.cat((attention4,up6),1)))\n",
    "        \n",
    "        upsample4 = self.UPsample4(conv4)            #H*W\n",
    "        up7 = self.UP7(upsample4)                    #H*W\n",
    "        up8 = self.UP8(up7)                          #H*W\n",
    "        #up9 = self.UP9(up8)       #H*W\n",
    "\n",
    "        return up8\n",
    "\n",
    "#torch.cuda.empty_cache()\n",
    "mynetwork = NET().to(device)\n",
    "#summary(mynetwork,(3,400,400), device = device)\n",
    "#%%\n",
    "net = NET().to('cuda')\n",
    "summary(net,(3,400,400), device = 'cuda')\n",
    "\n",
    "#%% Loss and optimizer\n",
    "class IoU(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(IoU, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        #mIoU=0\n",
    "        #iou=0\n",
    "        epsilon = 1e-7\n",
    "        \n",
    "        \n",
    "        tp = (targets * inputs).sum().to(torch.float32)\n",
    "        #tn = ((1 - targets) * (1 - inputs)).sum().to(torch.float32)\n",
    "        fp = ((1 - targets) * inputs).sum().to(torch.float32)\n",
    "        fn = (targets * (1 - inputs)).sum().to(torch.float32)\n",
    "        iou = (1-tp/(tp+fp+fn+epsilon)).to(torch.float32)\n",
    "        F1Score = (1-2*tp/(2*tp+fp+fn)).to(torch.float32)\n",
    "        #for i in range(inputs.shape[0]):\n",
    "        #    tp = (targets[i] * inputs[i]).sum().to(torch.float32)\n",
    "            #tn = ((1 - targets[i]) * (1 - inputs[i])).sum().to(torch.float32)\n",
    "         #   fp = ((1 - targets[i]) * inputs[i]).sum().to(torch.float32)\n",
    "        #    fn = (targets[i] * (1 - inputs[i])).sum().to(torch.float32)\n",
    "         #   iou += tp/(tp+fp+fn+epsilon)\n",
    "        #mIoU = iou/inputs.shape[0] \n",
    "        \n",
    "        bce = nn.BCELoss() \n",
    "        return 0.5*iou+0.5*bce(inputs,targets)+F1Score\n",
    "\n",
    "\n",
    "loss_fn = IoU().to(device)\n",
    "#loss_fn = nn.BCELoss() \n",
    "criterion = loss_fn\n",
    "\n",
    "optimizer = torch.optim.AdamW(mynetwork.parameters(), lr=0.003, betas=(0.9, 0.999), eps=1e-07, weight_decay=0.01, amsgrad=False)\n",
    "num_epochs =100\n",
    "scheduler = PolynomialLRDecay(optimizer, max_decay_steps=num_epochs, end_learning_rate=0.00001, power=0.9)\n",
    "\n",
    "#%% training\n",
    "\n",
    "#PATH = '/home/mostafa3_local/Documents/saved-models/2021_12_31_new_AddedMidflow.pth'\n",
    "PATH = '/home/mostafa3_local/Documents/saved-models/2021_12_31_trainOnDepth.pth'\n",
    "\n",
    "iter_loss_saved = []\n",
    "epoch_loss_saved = []\n",
    "valid_loss_saved = []\n",
    "\n",
    "since = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    mynetwork.train()\n",
    "    for i in range(n_iterations):\n",
    "\n",
    "        images = train_depth_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "        images = images.to(device)\n",
    "        labels = train_label_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mynetwork(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() \n",
    "        iter_loss_saved.append(loss.item())\n",
    "        \n",
    "        \n",
    "        if (i+1) % 2 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_iterations}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    scheduler.step(epoch)\n",
    "    mynetwork.eval() \n",
    "    valid_loss = 0.0\n",
    "    for i in range(int(validation_iteration)):\n",
    "\n",
    "      # Forward Pass\n",
    "      images = valid_depth_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "      images = images.to(device)\n",
    "      labels = valid_label_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      pred_valid_depth = mynetwork(images)\n",
    "      # Find the Loss\n",
    "      loss = criterion(pred_valid_depth,labels)\n",
    "      # Calculate Loss\n",
    "      valid_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1} \\t\\t Training Loss: {train_loss / n_iterations} \\t\\t Validation Loss: {valid_loss / validation_iteration}')\n",
    "    epoch_loss_saved.append(train_loss / n_iterations)\n",
    "    valid_loss_saved.append(valid_loss / validation_iteration)\n",
    "    print('minimum loss: ', np.min(valid_loss_saved))\n",
    "    \n",
    "    if valid_loss_saved[epoch] <= np.min(valid_loss_saved):\n",
    "        #torch.save(mynetwork, PATH)\n",
    "        print('model saved')\n",
    " \n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "#%%  saving model\n",
    "PATH = '/home/mostafa3_local/Documents/saved-models/2021_12_31_trainOnDepth_man.pth'\n",
    "torch.save(mynetwork, PATH)\n",
    "#mynetwork = torch.load(PATH)\n",
    "\n",
    "\n",
    "#%% Evaluation, disparity map as input\n",
    "\n",
    "\n",
    "plt.plot(epoch_loss_saved)\n",
    "plt.plot(valid_loss_saved)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend({'training loss','validation loss'})\n",
    "\n",
    "test_iteration = test_rgb.shape[0]/batch_size \n",
    "print(test_iteration)\n",
    "test_loss = 0\n",
    "pred_test_label = np.zeros((100,1,400,400))\n",
    "mynetwork.eval() \n",
    "with torch.no_grad():\n",
    "  for i in range(int(test_iteration)):\n",
    "      # Forward Pass\n",
    "      images = test_depth_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "      images = images.to(device)\n",
    "      labels = test_label_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "      labels = labels.to(device)\n",
    "      pred_test_label[batch_size*i:batch_size*(i+1),:,:,:] = mynetwork(images).to('cpu').numpy()\n",
    "      \n",
    "      pred_test_label0 = mynetwork(images)\n",
    "      # Find the Loss\n",
    "      loss = criterion(pred_test_label0,labels)\n",
    "      # Calculate Loss\n",
    "      test_loss += loss.item()\n",
    "#pred_test_depth = mynetwork(test_rgb_tns[batch_size*i:batch_size*(i+1),:,:,:])\n",
    "test_loss = test_loss/test_iteration\n",
    "print(f'test Loss: {test_loss}')\n",
    "\n",
    "\n",
    "print(pred_test_label.shape)\n",
    "pred_test_label1 = np.moveaxis(pred_test_label, 1, 3)\n",
    "print(pred_test_label1.shape)\n",
    "print(np.max(pred_test_label1))\n",
    "\n",
    "len(pred_test_label1)\n",
    "\n",
    "\n",
    "pred_train_label = np.zeros((420,1,400,400))\n",
    "with torch.no_grad():\n",
    "  for i in range(int(test_iteration)):\n",
    "      images = train_depth_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "      images = images.to(device)\n",
    "      pred_train_label[batch_size*i:batch_size*(i+1),:,:,:] = mynetwork(images).to('cpu').numpy()\n",
    "\n",
    "pred_train_label = np.moveaxis(pred_train_label, 1, 3)\n",
    "\n",
    "\n",
    "#%%  Evaluation\n",
    "\n",
    "pred_test_label2 = pred_test_label1.copy()\n",
    "for i in range(pred_test_label2.shape[0]):\n",
    "    pred_test_label2[i] = (pred_test_label2[i]>0.5)*1\n",
    "\n",
    "\n",
    "pred_test_label_trp = pred_test_label2.copy()\n",
    "for i in range(pred_test_label_trp.shape[0]):\n",
    "    pred_test_label_trp[i] = (pred_test_label2[i]==0)*1\n",
    "\n",
    "test_label_trp = test_label.copy()\n",
    "for i in range(test_label_trp.shape[0]):\n",
    "    test_label_trp[i] = (test_label[i]==0)*1\n",
    "\n",
    "\n",
    "mPrecition =0;mRecall=0;mAccuracy=0;mF1Score=0;mIoU =0\n",
    "\n",
    "#for i in range(pred_test_label2.shape[0]):\n",
    "for i in range(pred_test_label2.shape[0]):\n",
    "\n",
    "    TP = np.sum(np.multiply(pred_test_label2[i],test_label[i]))\n",
    "    FN = np.sum(np.multiply(pred_test_label_trp[i],test_label[i]))\n",
    "    FP = np.sum(np.multiply(pred_test_label2[i],test_label_trp[i]))\n",
    "    TN = np.sum(np.multiply(pred_test_label_trp[i],test_label_trp[i]))\n",
    "    \n",
    "    if TP+FP ==0:\n",
    "        Precition = 0\n",
    "        Recall = TP/(TP+FN)\n",
    "        Accuracy = (TP+TN)/(TN+TP+FP+FN)\n",
    "        F1Score = 2*TP/(2*TP+FP+FN)\n",
    "        IoU = TP/(TP+FP+FN)\n",
    "    else:\n",
    "        Precition = TP/(TP+FP)\n",
    "        Recall = TP/(TP+FN)\n",
    "        Accuracy = (TP+TN)/(TN+TP+FP+FN)\n",
    "        F1Score = 2*TP/(2*TP+FP+FN)\n",
    "        IoU = TP/(TP+FP+FN)\n",
    "    \n",
    "    mPrecition += Precition\n",
    "    mRecall += Recall\n",
    "    mAccuracy += Accuracy\n",
    "    mF1Score += F1Score\n",
    "    mIoU +=IoU\n",
    "\n",
    "print(f' mPrecition: {mPrecition/pred_test_label2.shape[0]} \\n mRecall: {mRecall/pred_test_label2.shape[0]} \\n mAccuracy: {mAccuracy/pred_test_label2.shape[0]} \\n mF1Score: {mF1Score/pred_test_label2.shape[0]} \\n mIoU: {mIoU/pred_test_label2.shape[0]}')\n",
    "    \n",
    "  \n",
    "#%% \n",
    "##################################################################################################\n",
    "######################################## Visualization ###########################################\n",
    "##################################################################################################\n",
    "\n",
    "\n",
    "def showdepth_train(n1,n2,n3):\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    fig.add_subplot(3, 3, 1)\n",
    "    plt.imshow(train_rgb[n1])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 4)\n",
    "    plt.imshow(train_label[n1])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 7)\n",
    "    plt.imshow(pred_train_label[n1])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 2)\n",
    "    plt.imshow(train_rgb[n2])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 5)\n",
    "    plt.imshow(train_label[n2])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 8)\n",
    "    plt.imshow(pred_train_label[n2])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 3)\n",
    "    plt.imshow(train_rgb[n3])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 6)\n",
    "    plt.imshow(train_label[n3])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 9)\n",
    "    plt.imshow(pred_train_label[n3])\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "def showdepths(n1,n2,n3):\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    fig.add_subplot(3, 3, 1)\n",
    "    plt.imshow(test_rgb[n1])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 4)\n",
    "    plt.imshow(test_label[n1])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 7)\n",
    "    plt.imshow(pred_test_label2[n1])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 2)\n",
    "    plt.imshow(test_rgb[n2])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 5)\n",
    "    plt.imshow(test_label[n2])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 8)\n",
    "    plt.imshow(pred_test_label2[n2])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 3)\n",
    "    plt.imshow(test_rgb[n3])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 6)\n",
    "    plt.imshow(test_label[n3])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 9)\n",
    "    plt.imshow(pred_test_label2[n3])\n",
    "    plt.axis('off')\n",
    "\n",
    "#%%\n",
    "showdepth_train(5,6,7)\n",
    "showdepths(30,31,32)\n",
    "\n",
    "\n",
    "#%% Continue training for depth estimation\n",
    "\n",
    "mynetwork.UP8 = depthwise_separable_conv_sig(16,3,1,1).to(device) # features[0] =16\n",
    "\n",
    "PATH = '/home/mostafa3_local/Documents/saved-models/2021_12_31_new_dualattention.pth'\n",
    "#mynetwork.load_state_dict(torch.load(PATH,map_location=torch.device('cuda')))\n",
    "mynetwork = torch.load(PATH)\n",
    "\n",
    "mynetwork(train_rgb_tns[0:5].to(device)).size()\n",
    "\n",
    " \n",
    "#%% scale invarient loss + gradient maching loss\n",
    "\n",
    "import kornia as K\n",
    "#scale invariant loss // inputs shoud be normalized between 0 and 1\n",
    "class SIGMLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(SIGMLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        g = torch.log(inputs+1) - torch.log(targets+1)\n",
    "        n = inputs.shape[0]*inputs.shape[1]*inputs.shape[2]*inputs.shape[3]\n",
    "        SI_loss = torch.mean(g**2) - (torch.sum(g)**2)/n**2\n",
    "        \n",
    "        \n",
    "        grads: torch.Tensor = K.filters.spatial_gradient(inputs, order=1)  # BxCx2xHxW\n",
    "        grads_xx = grads[:, :, 0]\n",
    "        grads_yx = grads[:, :, 1]\n",
    "        \n",
    "        grads: torch.Tensor = K.filters.spatial_gradient(targets, order=1)  # BxCx2xHxW\n",
    "        grads_xy = grads[:, :, 0]\n",
    "        grads_yy = grads[:, :, 1]\n",
    "        GM_loss = torch.mean(torch.abs(grads_xx-grads_xy)+ torch.abs(grads_yx-grads_yy))\n",
    "        \n",
    "        return SI_loss+GM_loss\n",
    "\n",
    "#%% SSIM + MSE loss\n",
    "from piqa import SSIM\n",
    "\n",
    "class SSIMLoss(SSIM):\n",
    "    def forward(self, x, y):\n",
    "        ssim_loss = 1 - super().forward(x, y)\n",
    "        mse_loss = nn.MSELoss()\n",
    "        #c\n",
    "        \n",
    "        #grads: torch.Tensor = K.filters.spatial_gradient(x, order=1)  # BxCx2xHxW\n",
    "        #grads_xx = grads[:, :, 0]\n",
    "        #grads_yx = grads[:, :, 1]\n",
    "        ##gradx = K.color.rgb_to_grayscale(grads_x + grads_y)\n",
    "        \n",
    "        #grads: torch.Tensor = K.filters.spatial_gradient(y, order=1)  # BxCx2xHxW\n",
    "        #grads_xy = grads[:, :, 0]\n",
    "        #grads_yy = grads[:, :, 1]\n",
    "        ##grady = K.color.rgb_to_grayscale(grads_x + grads_y)\n",
    "        #gradient_loss= torch.mean(torch.abs(grads_xx-grads_xy)+ torch.abs(grads_yx-grads_yy))\n",
    "        \n",
    "        return 0.7*ssim_loss + mse_loss(x,y)\n",
    "#%% scale invarient loss + gradient maching loss + ssim loss + MSE loss\n",
    "# this loss performs better \n",
    "from piqa import SSIM\n",
    "import kornia as K\n",
    "#scale invariant loss // inputs shoud be normalized between 0 and 1\n",
    "class SSIMLoss(SSIM):\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ssim_loss = 1 - super().forward(inputs, targets)\n",
    "        g = torch.log(inputs+1) - torch.log(targets+1)\n",
    "        n = inputs.shape[0]*inputs.shape[1]*inputs.shape[2]*inputs.shape[3]\n",
    "        SI_loss = torch.mean(g**2) - (torch.sum(g)**2)/n**2\n",
    "        \n",
    "        \n",
    "        grads: torch.Tensor = K.filters.spatial_gradient(inputs, order=1)  # BxCx2xHxW\n",
    "        grads_xx = grads[:, :, 0]\n",
    "        grads_yx = grads[:, :, 1]\n",
    "        \n",
    "        grads: torch.Tensor = K.filters.spatial_gradient(targets, order=1)  # BxCx2xHxW\n",
    "        grads_xy = grads[:, :, 0]\n",
    "        grads_yy = grads[:, :, 1]\n",
    "        GM_loss = torch.mean(torch.abs(grads_xx-grads_xy)+ torch.abs(grads_yx-grads_yy))\n",
    "        mse_loss = nn.MSELoss()\n",
    "\n",
    "        return SI_loss+0.5*GM_loss+0.6*ssim_loss+mse_loss(inputs,targets)\n",
    "#%%\n",
    "\n",
    "criterion = SSIMLoss().to(device) \n",
    "#optimizer = torch.optim.AdamW(mynetwork.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-07, weight_decay=0.01, amsgrad=False)\n",
    "\n",
    "optimizer = torch.optim.AdamW(mynetwork.parameters(), lr=0.005, betas=(0.9, 0.999), eps=1e-07, weight_decay=0.01, amsgrad=False)\n",
    "num_epochs =150\n",
    "scheduler = PolynomialLRDecay(optimizer, max_decay_steps=num_epochs, end_learning_rate=0.00001, power=0.9)\n",
    "\n",
    "criterion(train_depth_tns[5:10].to(device),train_depth_tns[5:10].to(device))\n",
    "print(device)\n",
    "#%%\n",
    "PATH = '/home/mostafa3_local/Documents/saved-models/2021_12_31_trainOnDepth_SIGM_SSIM.pth'\n",
    "\n",
    "#n_iterations =5\n",
    "#validation_iteration =5\n",
    "iter_loss_saved = []\n",
    "epoch_loss_saved = []\n",
    "valid_loss_saved = []\n",
    "\n",
    "since = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    mynetwork.train()\n",
    "    for i in range(n_iterations):\n",
    "\n",
    "        images = train_rgb_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "        images = images.to(device)\n",
    "        labels = train_depth_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mynetwork(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() \n",
    "        iter_loss_saved.append(loss.item())\n",
    "        \n",
    "        \n",
    "        if (i+1) % 2 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_iterations}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    scheduler.step(epoch)\n",
    "    mynetwork.eval() # Optional when not using Model Specific layer\n",
    "    valid_loss = 0.0\n",
    "    for i in range(int(validation_iteration)):\n",
    "\n",
    "      # Forward Pass\n",
    "      images = valid_rgb_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "      images = images.to(device)\n",
    "      labels = valid_depth_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      pred_valid_depth = mynetwork(images)\n",
    "      # Find the Loss\n",
    "      loss = criterion(pred_valid_depth,labels)\n",
    "      # Calculate Loss\n",
    "      valid_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1} \\t\\t Training Loss: {train_loss / n_iterations} \\t\\t Validation Loss: {valid_loss / validation_iteration}')\n",
    "    epoch_loss_saved.append(train_loss / n_iterations)\n",
    "    valid_loss_saved.append(valid_loss / validation_iteration)\n",
    "    print('minimum loss: ',np.min(valid_loss_saved))\n",
    "    \n",
    "    if valid_loss_saved[epoch] <= np.min(valid_loss_saved):\n",
    "        torch.save(mynetwork, PATH)\n",
    "        print('model saved')\n",
    "        \n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "#%%\n",
    "PATH = '/home/mostafa3_local/Documents/saved-models/2021_12_31_trainOnDepth_SIGM_SSIM_man.pth'\n",
    "\n",
    "torch.save(mynetwork, PATH)\n",
    "mynetwork = torch.load(PATH)\n",
    "\n",
    "#%% Evaluation\n",
    "\n",
    "\n",
    "plt.plot(epoch_loss_saved)\n",
    "plt.plot(valid_loss_saved)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend({'training loss','validation loss'})\n",
    "\n",
    "test_iteration = test_rgb.shape[0]/batch_size \n",
    "print(test_iteration)\n",
    "test_loss = 0\n",
    "pred_test_label = np.zeros((100,3,400,400))\n",
    "mynetwork.eval()\n",
    "with torch.no_grad():\n",
    "  for i in range(int(test_iteration)):\n",
    "      # Forward Pass\n",
    "      images = test_rgb_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "      images = images.to(device)\n",
    "      labels = test_depth_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "      labels = labels.to(device)\n",
    "      pred_test_label[batch_size*i:batch_size*(i+1),:,:,:] = mynetwork(images).to('cpu').numpy()\n",
    "      \n",
    "      pred_test_label0 = mynetwork(images)\n",
    "      # Find the Loss\n",
    "      loss = criterion(pred_test_label0,labels)\n",
    "      # Calculate Loss\n",
    "      test_loss += loss.item()\n",
    "#pred_test_depth = mynetwork(test_rgb_tns[batch_size*i:batch_size*(i+1),:,:,:])\n",
    "test_loss = test_loss/test_iteration\n",
    "print(f'test Loss: {test_loss}')\n",
    "\n",
    "\n",
    "print(pred_test_label.shape)\n",
    "pred_test_label1 = np.moveaxis(pred_test_label, 1, 3)\n",
    "print(pred_test_label1.shape)\n",
    "print(np.max(pred_test_label1))\n",
    "\n",
    "len(pred_test_label1)\n",
    "\n",
    "\n",
    "pred_test_depth3 = pred_test_label1 +1\n",
    "print(np.min(pred_test_depth3))\n",
    "print(np.max(pred_test_depth3))\n",
    "\n",
    "test_depth3 = test_depth +1\n",
    "print(np.min(test_depth3))\n",
    "print(np.max(test_depth3))\n",
    "\n",
    "AbsRel = np.mean(np.abs(pred_test_depth3-test_depth3)/test_depth3)\n",
    "RMSE = np.sqrt(np.mean(np.abs(pred_test_depth3-test_depth3)**2))\n",
    "RMSE_log = np.sqrt(np.mean(np.abs(np.log10(pred_test_depth3)-np.log10(test_depth3))**2))\n",
    "SqRel = np.mean(np.abs(pred_test_depth3-test_depth3)**2/test_depth3)\n",
    "\n",
    "print(f' AbsRel: {AbsRel} \\n RMSE: {RMSE} \\n RMSE_log: {RMSE_log} \\n SqRel: {SqRel} ')\n",
    "\n",
    "\n",
    "\n",
    "xnp = pred_test_depth3.reshape(100,480000)\n",
    "ynp = test_depth3.reshape(100,480000)     \n",
    "\n",
    "#%%\n",
    "thr = np.zeros(3)\n",
    "acc = np.zeros(3)\n",
    "for i in range(100):\n",
    "  for j in range(480000):\n",
    "      thr[0] += np.max([xnp[i][j]/ynp[i][j],ynp[i][j]/xnp[i][j]]) <1.25\n",
    "      thr[1] += np.max([xnp[i][j]/ynp[i][j],ynp[i][j]/xnp[i][j]]) <1.25**2\n",
    "      thr[2] += np.max([xnp[i][j]/ynp[i][j],ynp[i][j]/xnp[i][j]]) <1.25**3\n",
    "  acc += thr/480000\n",
    "  thr = np.zeros(3)\n",
    "\n",
    "print(f' Accuracy with threshold: {acc/(i+1)}')\n",
    "\n",
    "\n",
    "#%% \n",
    "##################################################################################################\n",
    "######################################## Visualization ###########################################\n",
    "##################################################################################################\n",
    "\n",
    "since = time.time()\n",
    "pred_train_label = np.zeros((420,3,400,400))\n",
    "with torch.no_grad():\n",
    "  for i in range(int(test_iteration)):\n",
    "      images = train_rgb_tns[batch_size*i:batch_size*(i+1),:,:,:]\n",
    "      images = images.to(device)\n",
    "      pred_train_label[batch_size*i:batch_size*(i+1),:,:,:] = mynetwork(images).to('cpu').numpy()\n",
    "      \n",
    "time_elapsed = time.time() - since\n",
    "print('420 frames complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "pred_train_label = np.moveaxis(pred_train_label, 1, 3)\n",
    "\n",
    "\n",
    "\n",
    "def showdepth_train(n1,n2,n3):\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    fig.add_subplot(3, 3, 1)\n",
    "    plt.imshow(train_rgb[n1])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 4)\n",
    "    plt.imshow(train_depth[n1])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 7)\n",
    "    plt.imshow(pred_train_label[n1])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 2)\n",
    "    plt.imshow(train_rgb[n2])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 5)\n",
    "    plt.imshow(train_depth[n2])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 8)\n",
    "    plt.imshow(pred_train_label[n2])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 3)\n",
    "    plt.imshow(train_rgb[n3])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 6)\n",
    "    plt.imshow(train_depth[n3])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 9)\n",
    "    plt.imshow(pred_train_label[n3])\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "def showdepths(n1,n2,n3):\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    fig.add_subplot(3, 3, 1)\n",
    "    plt.imshow(test_rgb[n1])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 4)\n",
    "    plt.imshow(test_depth[n1])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 7)\n",
    "    plt.imshow(pred_test_label1[n1])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 2)\n",
    "    plt.imshow(test_rgb[n2])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 5)\n",
    "    plt.imshow(test_depth[n2])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 8)\n",
    "    plt.imshow(pred_test_label1[n2])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 3)\n",
    "    plt.imshow(test_rgb[n3])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 6)\n",
    "    plt.imshow(test_depth[n3])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3, 3, 9)\n",
    "    plt.imshow(pred_test_label1[n3])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.imshow(test_rgb[5])\n",
    "plt.imshow(pred_test_label1[13])\n",
    "\n",
    "#%%\n",
    "showdepth_train(22,23,24)\n",
    "showdepths(20,21,22)\n",
    "#%%\n",
    "plt.imshow(pred_test_label1[28])\n",
    "\n",
    "a=pred_test_label1[28]\n",
    "a[:,:,2] = 0\n",
    "plt.imshow(a)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
